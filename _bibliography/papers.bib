---
---

@article{leduc2019automatic,
  abbr      = {{ECMFA'20}},
  index = 1,
  author    = {Leduc, Manuel and 
               Jouneaux, Gwendal and 
               Degueule, Thomas and 
               Le Guernic, Gurvan and 
               Barais, Olivier and 
               Combemale, Benoit},
  title     = {Automatic Generation of Truffle-based Interpreters for Domain-Specific Languages},
  journal   = {J. Object Technol. (Special Issue for ECMFA 2020 Proceedings)},
  volume    = {19},
  number    = {2},
  pages     = {1:1--21},
  year      = {2020},
  url       = {https://doi.org/10.5381/jot.2020.19.2.a1},
  doi       = {10.5381/jot.2020.19.2.a1},
  abstract  = {{ Numerous language workbenches have been proposed over the past decade to ease the 
              definition of Domain-Specific Languages (DSLs).Language workbenches enable DSL designers 
              to specify DSLs using high-level metalanguages, and to automatically generate their 
              implementation (e.g., parsers, interpreters) and tool support (e.g., editors, debuggers). 
              However, little attention has been given to the performance of the resulting interpreters. 
              In many domains where performance is key (e.g., scientific and high-performance computing), 
              this forces DSL designers to handcraft ad-hoc optimizations in interpreter implementations, 
              or lose compatibility with tool support. In this paper, we propose to systematically exploit 
              domain-specific information of DSL specifications to derive optimized Truffle-based language 
              interpreters executed over the GraalVM. Those optimizations are provided at no extra cost for 
              the DSL designer. They are of course not as efficient as handcrafted optimizations, but do not 
              require extra time or knowledge from the DSL designer (which industrial DSL designers often lack). 
              We implement our approach on top of the Eclipse Modeling Framework (EMF) by complementing its 
              existing compilation chain with Truffle-specific information, which drives GraalVM to benefit 
              from optimized just-in-time compilation. A key benefit of our approach is that it leverages existing
              DSL specifications and does not require additional information from DSL designers who remain oblivious 
              of Truffle’s low-level intricacies and JIT optimizations in general while staying compatible with tool 
              support. We evaluate our approach using a representative set of four DSLs and eight conforming programs. 
              Compared to the standard interpreters generated by EMF running on GraalVM, we observe an average speed-up 
              of x1.14, ranging from x1.07 to x1.26. Although the benefits vary slightly from one DSL or program to another, 
              we conclude that our approach yields substantial performance gains while remaining non-intrusive of EMF abstractions.}}
}

@inproceedings{jouneaux2021towards,
abbr={{Onward! 2021}},
index = 1,
month = Oct,
author = {Jouneaux, Gwendal and Barais, Olivier and Combemale, Benoit and Mussbacher, Gunter},
title = {Towards Self-Adaptable Languages},
year = {2021},
isbn = {9781450391108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://hal.inria.fr/hal-03318816v1},
doi = {10.1145/3486607.3486753},
booktitle = {Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {97–113},
numpages = {17},
keywords = {self-adaptation, software language, L-MODA framework, trade-off analysis, feedback loop},
location = {Chicago, IL, USA},
series = {Onward! 2021},
abstract = {Over recent years, self-adaptation has become a concern for many software systems
that have to operate in complex and changing environments. At the core of self-adaptation,
there is a feedback loop and associated trade-off reasoning to decide on the best
course of action. However, existing software languages do not abstract the development
and execution of such feedback loops for self-adaptable systems. Developers have to
fall back to ad-hoc solutions to implement self-adaptable systems, often with wide-ranging
design implications (e.g., explicit MAPE-K loop). Furthermore, existing software languages
do not capitalize on monitored usage data of a language and its modeling environment.
This hinders the continuous and automatic evolution of a software language based on
feedback loops from the modeling environment and runtime software system. To address
the aforementioned issues, this paper introduces the concept of Self-Adaptable Language
(SAL) to abstract the feedback loops at both system and language levels. We propose
L-MODA (Language, Models, and Data) as a conceptual reference framework that characterizes
the possible feedback loops abstracted into a SAL. To demonstrate SALs, we present
emerging results on the abstraction of the system feedback loop into the language
semantics. We report on the concept of Self-Adaptable Virtual Machines as an example
of semantic adaptation in a language interpreter and present a roadmap for SALs.}
}


@inproceedings{jouneaux2021SEALS, 
    ABBR = {SLE 2021},
    INDEX = 2,
    TITLE = {{SEALS: A Framework for Building Self-Adaptive Virtual Machines}}, 
    AUTHOR = {Jouneaux, Gwendal and Barais, Olivier and Combemale, Benoit and Mussbacher, Gunter}, 
    URL = {https://hal.inria.fr/hal-03355253}, 
    BOOKTITLE = {{Proceedings of the 14th ACM SIGPLAN International Conference on Software Language Engineering (SLE '21)}},
    ADDRESS = {Chicago, United States}, 
    YEAR = {2021}, 
    MONTH = Oct, 
    DOI = {10.1145/3486608.3486912},
    ABSTRACT = {Over recent years, self-adaptation has become a major concern for software systems 
    that evolve in changing environments. While expert developers may choose a manual implementation 
    when self-adaptation is the primary concern, self-adaptation should be abstracted for non-expert 
    developers or when it is a secondary concern. We present SEALS, a framework for building self-adaptive 
    virtual machines for domain specific languages. This framework provides first-class entities for 
    the language engineer to promote domain-specific feedback loops in the definition of the DSL 
    operational semantics. In particular, the framework supports the definition of (i) the abstract 
    syntax and the semantics of the language as well as the correctness envelope defining the acceptable 
    semantics for a domain concept, (ii) the feedback loop and associated trade-off reasoning, and 
    (iii) the adaptations and the predictive model of their impact on the trade-off. We use this 
    framework to build three languages with self-adaptive virtual machines and discuss the relevance 
    of the abstractions, effectiveness of correctness envelopes, and compare their code size and 
    performance results to their manually implemented counterparts. We show that the framework provides 
    suitable abstractions for the implementation of self-adaptive operational semantics while introducing 
    little performance overhead compared to a manual implementation.}
}